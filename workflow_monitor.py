#!/usr/bin/env python3
"""
Workflow Monitor - GitHub API Integration
Monitors GitHub Actions workflows for failures and retrieves error information.
"""

import os
import sys
import requests
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

from healing_config import config

@dataclass
class WorkflowRun:
    """Represents a GitHub Actions workflow run."""
    id: int
    workflow_name: str
    status: str
    conclusion: str
    created_at: str
    updated_at: str
    head_sha: str
    head_branch: str
    html_url: str
    jobs_url: str
    logs_url: str

@dataclass
class JobRun:
    """Represents a job within a workflow run."""
    id: int
    name: str
    status: str
    conclusion: str
    started_at: str
    completed_at: str
    html_url: str
    logs_url: str

class WorkflowMonitor:
    """Monitors GitHub Actions workflows for failures."""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.session = requests.Session()

        # Set up authentication
        if config.github_token:
            self.session.headers.update({
                'Authorization': f'token {config.github_token}',
                'Accept': 'application/vnd.github.v3+json',
                'User-Agent': 'CTMM-Workflow-Healing-System/1.0'
            })
        else:
            self.logger.warning("No GitHub token provided - API rate limits will apply")

    def get_failed_workflows(self, hours_back: int = None) -> List[WorkflowRun]:
        """Get all failed workflow runs within the specified time range."""
        if hours_back is None:
            hours_back = config.max_workflow_age_hours

        since = datetime.utcnow() - timedelta(hours=hours_back)
        failed_runs = []

        try:
            # Get workflow runs for the repository
            url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/runs"
            params = {
                'status': 'completed',
                'per_page': 100,
                'created': f'>{since.isoformat()}Z'
            }

            response = self.session.get(url, params=params)
            response.raise_for_status()

            data = response.json()

            for run_data in data.get('workflow_runs', []):
                # Check if this is a monitored workflow and has failed
                workflow_name = run_data['name']
                workflow_file = os.path.basename(run_data['path'])

                if (config.is_monitored_workflow(workflow_file) and
                    run_data['conclusion'] in config.failure_states):

                    workflow_run = WorkflowRun(
                        id=run_data['id'],
                        workflow_name=workflow_name,
                        status=run_data['status'],
                        conclusion=run_data['conclusion'],
                        created_at=run_data['created_at'],
                        updated_at=run_data['updated_at'],
                        head_sha=run_data['head_sha'],
                        head_branch=run_data['head_branch'],
                        html_url=run_data['html_url'],
                        jobs_url=run_data['jobs_url'],
                        logs_url=run_data['logs_url']
                    )

                    failed_runs.append(workflow_run)
                    self.logger.info(f"Found failed workflow: {workflow_name} (ID: {run_data['id']})")

            self.logger.info(f"Found {len(failed_runs)} failed workflow runs")
            return failed_runs

        except requests.RequestException as e:
            self.logger.error(f"Failed to fetch workflow runs: {e}")
            return []

    def get_workflow_jobs(self, run_id: int) -> List[JobRun]:
        """Get all jobs for a specific workflow run."""
        try:
            url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/runs/{run_id}/jobs"
            response = self.session.get(url)
            response.raise_for_status()

            data = response.json()
            jobs = []

            for job_data in data.get('jobs', []):
                job = JobRun(
                    id=job_data['id'],
                    name=job_data['name'],
                    status=job_data['status'],
                    conclusion=job_data.get('conclusion'),
                    started_at=job_data.get('started_at'),
                    completed_at=job_data.get('completed_at'),
                    html_url=job_data['html_url'],
                    logs_url=f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/jobs/{job_data['id']}/logs"
                )
                jobs.append(job)

            return jobs

        except requests.RequestException as e:
            self.logger.error(f"Failed to fetch jobs for run {run_id}: {e}")
            return []

    def get_job_logs(self, job_id: int) -> str:
        """Get the logs for a specific job."""
        try:
            url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/jobs/{job_id}/logs"
            response = self.session.get(url)
            response.raise_for_status()

            # The response is the raw log text
            return response.text

        except requests.RequestException as e:
            self.logger.error(f"Failed to fetch logs for job {job_id}: {e}")
            return ""

    def get_workflow_run_logs(self, run_id: int) -> Dict[str, str]:
        """Get logs for all jobs in a workflow run."""
        jobs = self.get_workflow_jobs(run_id)
        logs = {}

        for job in jobs:
            if job.conclusion in config.failure_states:
                job_logs = self.get_job_logs(job.id)
                logs[job.name] = job_logs
                self.logger.debug(f"Retrieved logs for failed job: {job.name}")

        return logs

    def restart_workflow(self, run_id: int) -> bool:
        """Restart a failed workflow run."""
        try:
            url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/runs/{run_id}/rerun"
            response = self.session.post(url)
            response.raise_for_status()

            self.logger.info(f"Successfully restarted workflow run {run_id}")
            return True

        except requests.RequestException as e:
            self.logger.error(f"Failed to restart workflow run {run_id}: {e}")
            return False

    def get_recent_workflow_status(self, workflow_name: str, branch: str = 'main') -> Optional[str]:
        """Get the status of the most recent run for a specific workflow."""
        try:
            url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/runs"
            params = {
                'workflow_id': workflow_name,
                'branch': branch,
                'per_page': 1
            }

            response = self.session.get(url, params=params)
            response.raise_for_status()

            data = response.json()
            runs = data.get('workflow_runs', [])

            if runs:
                return runs[0].get('conclusion')

            return None

        except requests.RequestException as e:
            self.logger.error(f"Failed to get workflow status for {workflow_name}: {e}")
            return None

    def wait_for_workflow_completion(self, run_id: int, timeout_minutes: int = 30) -> Optional[str]:
        """Wait for a workflow run to complete and return its conclusion."""
        import time

        start_time = time.time()
        timeout_seconds = timeout_minutes * 60

        while time.time() - start_time < timeout_seconds:
            try:
                url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/actions/runs/{run_id}"
                response = self.session.get(url)
                response.raise_for_status()

                data = response.json()
                status = data.get('status')
                conclusion = data.get('conclusion')

                if status == 'completed':
                    self.logger.info(f"Workflow run {run_id} completed with conclusion: {conclusion}")
                    return conclusion

                self.logger.debug(f"Workflow run {run_id} still running (status: {status})")
                time.sleep(30)  # Check every 30 seconds

            except requests.RequestException as e:
                self.logger.error(f"Error checking workflow status: {e}")
                time.sleep(60)  # Wait longer on error

        self.logger.warning(f"Timeout waiting for workflow run {run_id} to complete")
        return None

    def get_open_pull_requests(self) -> List[Dict]:
        """Get all open pull requests for the repository."""
        try:
            url = f"{config.api_base_url}/repos/{config.repo_owner}/{config.repo_name}/pulls"
            params = {'state': 'open', 'per_page': 100}

            response = self.session.get(url, params=params)
            response.raise_for_status()

            return response.json()

        except requests.RequestException as e:
            self.logger.error(f"Failed to fetch open pull requests: {e}")
            return []

    def get_healing_prs(self) -> List[Dict]:
        """Get open pull requests created by the healing system."""
        prs = self.get_open_pull_requests()
        healing_prs = []

        for pr in prs:
            if (pr['head']['ref'].startswith(config.pr_settings['branch_prefix']) or
                pr['title'].startswith(config.pr_settings['pr_title_prefix'])):
                healing_prs.append(pr)

        return healing_prs

def main():
    """Test the workflow monitor functionality."""
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

    monitor = WorkflowMonitor()

    print("üîç Testing Workflow Monitor")
    print("=" * 50)

    # Test configuration validation
    config_issues = config.validate_config()
    if config_issues:
        print("‚ùå Configuration Issues:")
        for issue in config_issues:
            print(f"   - {issue}")
        return

    print("‚úÖ Configuration validated")

    # Get failed workflows
    print("\nüìã Fetching failed workflows...")
    failed_workflows = monitor.get_failed_workflows()

    if not failed_workflows:
        print("‚úÖ No failed workflows found")
    else:
        print(f"‚ö†Ô∏è  Found {len(failed_workflows)} failed workflows:")
        for workflow in failed_workflows[:3]:  # Show first 3
            print(f"   - {workflow.workflow_name} (ID: {workflow.id}, Status: {workflow.conclusion})")

    # Check for healing PRs
    print("\nüîß Checking for existing healing PRs...")
    healing_prs = monitor.get_healing_prs()
    print(f"Found {len(healing_prs)} existing healing PRs")

    print("\n‚úÖ Workflow monitor test completed")

if __name__ == "__main__":
    main()
