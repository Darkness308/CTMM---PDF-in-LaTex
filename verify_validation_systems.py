#!/usr/bin/env python3
"""
Enhanced Validation Systems Verification Script

This script verifies that enhanced validation systems are operational including:
1. Error handling improvements
2. Validation script integration
3. Comprehensive reporting capabilities
4. Cross-system validation coordination
"""

import subprocess
import sys
from pathlib import Path

def run_command(cmd, description=""):
    """Run a command and return success status and output."""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        success = result.returncode == 0
        return success, result.stdout.strip(), result.stderr.strip()
    except Exception as e:
        return False, "", str(e)

def check_validation_infrastructure():
    """Check that validation infrastructure is comprehensive."""
    
    print("=" * 80)
    print("ENHANCED VALIDATION SYSTEMS VERIFICATION")
    print("=" * 80)
    print("Verifying enhanced validation systems and error handling.\n")
    
    # Check for key validation scripts
    validation_scripts = [
        "validate_pr.py",
        "validate_workflow_syntax.py",
        "validate_workflow_versions.py",
        "validate_latex_syntax.py"
    ]
    
    existing_scripts = []
    for script in validation_scripts:
        if Path(script).exists():
            existing_scripts.append(script)
    
    print(f"üìä Validation infrastructure:")
    print(f"   Expected scripts: {len(validation_scripts)}")
    print(f"   Found scripts: {len(existing_scripts)}")
    
    for script in existing_scripts:
        print(f"   ‚úÖ {script}")
    
    missing_scripts = set(validation_scripts) - set(existing_scripts)
    for script in missing_scripts:
        print(f"   ‚ùå {script} (missing)")
    
    if len(existing_scripts) < len(validation_scripts) * 0.75:
        print("‚ùå Insufficient validation infrastructure")
        return False
    
    print("‚úÖ Validation infrastructure is comprehensive")
    return True

def check_error_handling():
    """Test enhanced error handling in validation systems."""
    
    print("\nüö® ERROR HANDLING VERIFICATION")
    print("-" * 50)
    
    # Test error handling scenarios
    error_tests = [
        ("PR validation with no changes", "python3 validate_pr.py --skip-build"),
        ("CTMM build system", "python3 ctmm_build.py"),
        ("LaTeX validation", "python3 latex_validator.py main.tex")
    ]
    
    error_handling_works = 0
    
    for test_name, command in error_tests:
        success, stdout, stderr = run_command(command)
        
        # Check if meaningful error messages are provided
        total_output = len(stdout) + len(stderr)
        
        if total_output > 50:  # Substantial feedback provided
            print(f"‚úÖ {test_name}: Provides meaningful feedback ({total_output} chars)")
            error_handling_works += 1
        else:
            print(f"‚ö†Ô∏è  {test_name}: Limited feedback ({total_output} chars)")
    
    print(f"\nüìä Error handling: {error_handling_works}/{len(error_tests)} tests provide good feedback")
    
    return error_handling_works >= len(error_tests) // 2

def check_cross_system_validation():
    """Check that validation systems work together."""
    
    print("\nüîó CROSS-SYSTEM VALIDATION")
    print("-" * 50)
    
    # Test that verification scripts can run validation scripts
    cross_validation_tests = [
        ("Verification can run PR validation", "python3 verify_issue_914_fix.py"),
        ("All systems orchestration", "python3 verify_all_systems.py"),
        ("Copilot readiness check", "python3 verify_copilot_readiness.py")
    ]
    
    working_integrations = 0
    
    for test_name, command in cross_validation_tests:
        if not Path(command.split()[-1]).exists():
            print(f"‚ö†Ô∏è  {test_name}: Script not found")
            continue
            
        success, stdout, stderr = run_command(command)
        
        # Check if the script provides comprehensive output
        if len(stdout) > 100 or "VERIFICATION" in stdout:
            print(f"‚úÖ {test_name}: Integration functional")
            working_integrations += 1
        else:
            print(f"‚ùå {test_name}: Integration issues")
    
    print(f"\nüìä Cross-system validation: {working_integrations} integrations working")
    
    return working_integrations > 0

def check_reporting_capabilities():
    """Check enhanced reporting capabilities."""
    
    print("\nüìä REPORTING CAPABILITIES")
    print("-" * 50)
    
    # Check for comprehensive reporting in scripts
    reporting_features = []
    
    # Check if validation scripts provide structured output
    success, stdout, stderr = run_command("python3 validate_pr.py --help")
    if success and "verbose" in stdout.lower():
        reporting_features.append("PR validation supports verbose output")
    
    # Check if verification scripts provide detailed reports
    verification_files = list(Path(".").glob("verify_*.py"))
    if len(verification_files) >= 5:
        reporting_features.append(f"{len(verification_files)} verification scripts for comprehensive coverage")
    
    # Check for resolution documentation
    resolution_files = list(Path(".").glob("ISSUE_*_RESOLUTION.md"))
    if len(resolution_files) >= 10:
        reporting_features.append(f"{len(resolution_files)} resolution documents for historical tracking")
    
    print("üìã Reporting features found:")
    for feature in reporting_features:
        print(f"   ‚úÖ {feature}")
    
    if len(reporting_features) < 2:
        print("‚ùå Limited reporting capabilities")
        return False
    
    print("‚úÖ Enhanced reporting capabilities operational")
    return True

def main():
    """Main enhanced validation systems verification function."""
    
    print("üéØ ENHANCED VALIDATION SYSTEMS VERIFICATION")
    print("Verifying comprehensive validation infrastructure improvements\n")
    
    tests = [
        ("Validation infrastructure", check_validation_infrastructure),
        ("Error handling", check_error_handling),
        ("Cross-system validation", check_cross_system_validation),
        ("Reporting capabilities", check_reporting_capabilities)
    ]
    
    all_passed = True
    passed_count = 0
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            if result:
                passed_count += 1
            else:
                all_passed = False
        except Exception as e:
            print(f"‚ùå TEST ERROR in {test_name}: {e}")
            all_passed = False
    
    print("\n" + "=" * 80)
    print("ENHANCED VALIDATION SYSTEMS RESULTS")
    print("=" * 80)
    
    if passed_count >= 3:  # Require most tests to pass
        print("üéâ ENHANCED VALIDATION SYSTEMS: SUCCESS")
        print(f"‚úÖ {passed_count}/{len(tests)} validation categories passed")
        print("‚úÖ Comprehensive validation infrastructure operational")
        print("‚úÖ Enhanced error handling functional")
        print("‚úÖ Cross-system validation working")
        print("‚úÖ Reporting capabilities enhanced")
        print("‚úÖ Validation systems ready for production use")
        return True
    else:
        print("‚ùå ENHANCED VALIDATION SYSTEMS: NEEDS IMPROVEMENT")
        print(f"   Only {passed_count}/{len(tests)} validation categories passed")
        print("   Some validation system components need attention")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)